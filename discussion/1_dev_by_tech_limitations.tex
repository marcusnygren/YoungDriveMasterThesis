%\section{Technical development}
\section{How is the Development Affected by the Technical Possibilities?}
%\section{What in the development has been affected by the technical possibilities?}

As devices were limited, a goal was to make the app available on as many devices as possible. Creating a hybrid app using web technologies using Meteor made the app available both as a native app on Android and iOS devices, as well as on the web. On the other hand, this is not enough: the pre-evaluation showed that only 3 out of 16 had a smartphone today \citep{youngdrive-statistics}.

As internet is accessible but expensive and often used seldom, the app does not provide rich media or simulations, but focuses instead on creative design possibilities using multiple-choice, also having cognitive load and scaffolding in mind. The interviews and observations from iteration 4 details that the coaches are happy with the user friendliness of the app, and that the training in its current form has high value for the coaches. On the other hand, images could probably be used to lower misconceptions in language, and a future wish of the coaches is to have the manuals accessible via mobile as well, which includes both text and images.

Most of the coaches have been first-time smartphone users. Letting them continuously test and co-create the app has created a tailor-made app from their needs and conditions. It may be surprising how simple design solutions using text and clear visuals can provide rich learning feedback, mentioned by Nocol \cite{nicol}. On the other hand, since it is so tailor-made, it needs to be examined if to make the app work in other countries than Uganda and Zambia, where design and technology preferences might be different.

That the app should work offline, and still be able to push quiz results when it gets online, has been a challenge. It can be hard to find good existing approaches for some technical platforms, but for Meteor plugins such as GroundDB proved very usable, since it is also automatic. In other apps in developing countries sometimes the user decides themselves when to push data, but in this case, quiz results are so small in size that it was unnecessary. This might be reconsidered in the future, for example if answers are no longer solely multiple-choice.

Below, reasons the development was negatively affected by the technical constrains are highlighted.

\subsection{Online Data Collection was Needed Earlier}
To test on all of the coaches in Uganda, it would have been preferable if data collection would have happened via the app instead of manually already in iteration 3, since there would be more than 10 test subjects, which had been the limit in Zambia. This was planned for, but technical implications with Meteor made it delayed. Done manually, not all data was recoded in iteration 3, which made it harder to draw conclusions from the quiz results. Both Lopez \cite{une-terre} and \cite{timo-ropinski-liu} explains how visualization techniques (like parallel coordinates) are more suitable for large data sets. This can be read more about below.

\subsection{Problems with Internet Access}
In day 3 of the Zambia coach training in iteration 2, iOS no longer allowed uncertified app installs from the computer: you needed to have paid a license even for unreleased apps, being a "Trusted developer". This stopped the app from being able to be installed on all the iOS devices, so that only the web version could be used. Thus, only the web app was tested on Wednesday and onwards. This was a problem, as the app regularly crashed at refresh because of low internet capacity. Sometimes, it was needed to go to the other office where there was wifi, to refresh the webpage, and go back to the location. Going away from the training would of course not be viable Josefina, as she would miss valuable time teaching the youth. A similar situation appeared for the current author: while it was positive that these challenges were identified thanks to real-world testing, valuable time testing the actual functionality of the app was lost, with less feedback for continued development as a result.

\subsection{Backwards Capability Issues} \label{backwards-capability}
Upgrading from version 1.2 to 1.3 during Iteration 3 was a good example of technical limitations. It took a lot of time, but when it was discovered that version 1.2 did not work for old Android devices, the changes needed to be reverted. In another project, new Android versions might have been acceptable, but here a "better" version of software was not viable.

Meteor 1.2 had several disadvantages: while it worked for all devices, it did not support React.js Meteor 1.3 was released, which promised a better developer experience, with JavaScript ES6 support, and access to Node Package Manager (npm), plus official support for React.js. In 1.2, only some npm packages had been adapted for Meteor, and tools such as Webpack could not be used.

The downsides were discovered after implementation: there were missing backward compatibility to the older of the Android devices. The backup would be the web version, but at the time of iteration 3, there were no Heroku build-pack for Meteor 1.3, making the website to crash. This was however fixed before iteration 4, which is why Meteor 1.3 was kept.

\subsection{No Time Assigned for Writing Automatic Tests}
The project would have benefited from passing automatic tests before doing user tests. While automatic tests were never written because of time constraints, since iteration 3, beta releases and production releases were separated into different domains, using Heroku's staging environment, with a different GitHub branch for each new iteration. Even so, doing automated tests would have helped to find things that had worked previously but not in a new version, or finding bugs with new functionality like client-server communication. This would have made interactions with coaches more efficient, since the users would have been exposed to an app with less accidental errors.

\subsection{Difficulties Comparing Quiz Results between Iterations}
It would be highly interesting to compare the quiz results between different iterations of the app, to measure how much learning has increased. However, the educational range and knowledge between Zambia and Uganda is too large to draw such conclusions: while all of the Zambia coaches had 100\% correct answers on quiz 3 "Financial literacy" (iteration 2), the same number for Uganda was 91.8\% (iteration 4). This makes further conclusions very hard, more than from informed guesses and observations. See more about this in section \ref{sec:internationalization}. How to empirically measure and compare learning effectiveness between different countries could be interesting future work.

