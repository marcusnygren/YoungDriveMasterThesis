\subsection{Discussion}

The quantative and qualitative data from iteration 2 shows that the app works for "validating the coaches' level of knowledge during their education", which was the main purpose of the master thesis (see section \ref{rq}. Now, the app should be tested in Uganda as well, and there can be an increased focus on "distance training" and "certify all staff".

Iteration 2 has translated the theoretical understanding of answering research question 1, 2, 3 and 5 into practical experience. Now there are observable evidence for what the interactions from Iteration 1 showed:

\begin{itemize}
\item The purpose of the coach training should be to prepare the coach in having great youth sessions
\item Therefore, this is what the quizzess should assess
\item What it really means being a good YoungDrive coach, is having good youth sessions
\end{itemize}

\subsubsection{Validating the coaches' level of knowledge}
The quiz results data shows that a lecture is still currently more valuable than taking a quiz in the app two times to improve (15.0\% to 12.8\%). For iteration 2, work on answering research question 4 has started. While the teacher has appreciated the multiple-choice assessment, challenges of designing test questions to support entrepreneurial learning has been found. It is clear that the app is valuable for assessment, increasing coach self-awareness and being a valuable indicator for the teacher. However, the questions formulated scores low on Bloom's revised taxonomy \cite{bloom} compared with YoungDrive's educational objectives for the topics.

There are previously found issues with using multiple-choice for assessment and learning, but they seem to become especially relevant in the context of teaching entrepreneurship.

Either question formulation needs to be improved, or creative design solutions needs to be experimented with which can increase coach understanding and identify and reduce guessing. This needs to be further investigated for iteration 3.

Test with university student scored 100\% correct, means that common sense can go a long way, and that the results can't be 100\% trustworthy, and that multiple-choice questions has serious issues - this, we already knew during and before the coach training - but it needs to be taken care of. Similarly business and leadership experience for the coach seems to lead to a higher quiz average, while a low quiz average can't seem to be relatable to any of the coach characteristics found during the interviews. This makes it hard to design the app for different types of coaches, without testing other parameters, which should be done in iteration 4 for the summative test.

\subsubsection{Distance learning}
In addition to the formative app tests, workshop \# 2 heavily informs what is necessary when designing for use case 2, distance learning: preparing a session in regards to building confidence. The results from the workshop are somewhat surprising, factors not only those that relate to the four parameters from iteration 1 ("I am well prepared" and "I believe in myself"), but for some also "I believe in God" or "I am certified" (which relates to purpose 3 of the app). These should be considered for iteration 3.

Further, app tests expose how the app is currently not actively designed with learning in mind, and thus not distance learning. This is unfortunate, both because distance learning is important, and as the app test with refugee innovators shows that there is an opportunity doing entrepreneurship training in rural areas outside of YoungDrive's coverage area. In order for online coach-training to work for distance learning, learning and feedback, and not only assessment, is however essential.

While it may be technically possible, the teacher desires the app support her during the coach training, not replace her. Therefore, completely replacing the teacher with an app should be avoided. The teacher is very important for giving coaching and educating in a way that the app can't. But the teacher can also be empowered by the app. For the future, Josefina would have liked to be able to stop coaches from having taught, if they do not have 90-100 \% correct information on the subject. Today, Josefina can not assess this. This means that some coaches, are teaching incorrect information to hundreds of youth. Here, the quiz has a very good need to fill.

If wrong on an answer, the app today has no means of giving high pay-off tips to get to 100\%, or exposing you to deliberate practice or perceptual exposure. If the coach gets 9/10 correct answers reliably, or gets 5/10 answers with guesses, the coach still needs to retake all answers, not having learned the correct answer before taking the quiz again.

How to develop the app to solve these issues, is not obvious. Multiple strategies could and should be used. The app could benefit from introducing smart feedback encouraging a growth mindset ("You did not get 100\% \textit{yet}") \cite{dweck}.

\subsection{Next iteration}
After the meeting with the partner and expert group, the following was concluded from iteration \#2:

\begin{itemize}
\item The app is partly working on assessment now, but not for learning. Are coaches really learning via the app, especially learning to be better coaches?
  \begin{itemize}
    \item Multiple-choice is flawed in its current form. How can guesses be identified and reduced in a multiple-choice format? How can answering questions improve confidence and encourage learning?
    \item How can questions be formulated in a way that teaches entrepreneurship, which is so practical?
  \end{itemize}
\item The need for a field app still feels relevant (especially for sessions long since the coach training)
  \begin{itemize}
    \item An app could be used, either before you start planning (to guide what you need to study the most on), or after you think you are ready (so you can assess and improve).
    \item When designing the app, it is concluded that an app for coach training, and an app to use before a youth session, should be able to be the same app if possible, since the purpose of preparing the coach to be great with its youth session is the same.
    \item Discussing the importance of self-reflection after a youth session with Josefina, led to asking more of such questions in coach quizzes. While Fun Atmosphere can be hard to assess using multiple-choice, can Correct Structure and Time Management be assessed?
  \end{itemize}
\end{itemize}

After the partner and expert meeting, it was decided that the following needs to be done for iteration 3:

\begin{itemize}
  \item Make sure that the coach actually learnes the desired educational objectives
  \begin{itemize}
    \item Create a new quiz guided by Josefina, "Are you ready for Session 9?", also to test if Correct Structure and Time Management could be assessed using multiple-choice
    \item See if design additions to multiple-choice can increase learning in-line with Bloom's revised taxonomy
  \end{itemize}
  \item Design quiz app for learning, focus on field app, and have a design that works stand-alone from the YoungDrive coach training in mind.
  \begin{itemize}
    \item Investigate the effect of giving growth mindset feedback in the app (The Power of Yet approach)
  \end{itemize}
  \item Test if the app created in Zambia could work also in Uganda
    \begin{itemize}
      \item This also means converting all the questions from the new (Zambia) manual to the old (Uganda) manual, since both structure and content of the manuals has changed.
    \end{itemize}
\end{itemize}
